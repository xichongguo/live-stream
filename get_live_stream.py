# File: get_live_stream.py
# Description: æŠ“å–å¤šæºç›´æ’­æµï¼Œæ™ºèƒ½åˆ†ç±» + å¤®è§†æœ‰æ•ˆæ€§æ£€æµ‹ + ç™½åå•ä¼˜å…ˆ
# Author: Assistant
# Date: 2025-11-03

import requests
import os
from urllib.parse import unquote, urlparse, parse_qs, urlunparse
from datetime import datetime
from collections import Counter
import time


# ================== Configuration ==================
API_URL = "https://lwydapi.xichongtv.cn/a/appLive/info/35137_b14710553f9b43349f46d33cc2b7fcfd"
PARAMS = {
    'deviceType': '1',
    'centerId': '9',
    'deviceToken': 'beb09666-78c0-4ae8-94e9-b0b4180a31be',
    'latitudeValue': '0',
    'areaId': '907',
    'appCenterId': '907',
    'isTest': '0',
    'longitudeValue': '0',
    'deviceVersionType': 'android',
    'versionCodeGlobal': '5009037'
}
HEADERS = {
    'User-Agent': 'okhttp/3.12.12',
}

# --- æºåœ°å€æ›´æ–° ---
REMOTE_WHITELIST_URL = "https://raw.githubusercontent.com/xichongguo/live-stream/main/whitelist.txt"
TV_M3U_URL = "https://raw.githubusercontent.com/wwb521/live/refs/heads/main/tv.m3u"
GUOVIN_IPTV_URL = "https://cdn.jsdelivr.net/gh/Guovin/iptv-api@gd/output/result.txt"

WHITELIST_TIMEOUT = 15
CHECK_TIMEOUT = 5
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

OUTPUT_DIR = "live"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "current.m3u8")


# ---------------- åˆ†ç±»è§„åˆ™ ----------------
CATEGORY_MAP = {
    'å¤®è§†': ['cctv', 'ä¸­å¤®'],
    'å«è§†': ['å«è§†', 'æ¹–å—', 'æµ™æ±Ÿ', 'æ±Ÿè‹', 'ä¸œæ–¹', 'åŒ—äº¬', 'å¹¿ä¸œ', 'æ·±åœ³', 'å››å·', 'æ¹–åŒ—', 'è¾½å®',
             'ä¸œå—', 'å¤©æ´¥', 'é‡åº†', 'é»‘é¾™æ±Ÿ', 'å±±ä¸œ', 'å®‰å¾½', 'äº‘å—', 'é™•è¥¿', 'ç”˜è‚ƒ', 'æ–°ç–†',
             'å†…è’™å¤', 'å‰æ—', 'æ²³åŒ—', 'å±±è¥¿', 'å¹¿è¥¿', 'æ±Ÿè¥¿', 'ç¦å»º', 'è´µå·', 'æµ·å—'],
    'è½®æ’­é¢‘é“': [
        'ç”µè§†å‰§', 'ç”µå½±', 'å½±é™¢', 'å½±è§†é¢‘é“', 'å½±è§†', 'ç²¾é€‰', 'è½®æ’­', 'å›çœ‹', 'é‡æ¸©',
        'ç»å…¸', 'æ€€æ—§', 'å‰§åœº', 'å¤§ç‰‡', 'çƒ­æ’­', 'ç‚¹æ’­', 'è™ç‰™', 'æ–—é±¼', 'ç›´æ’­+',
        'LIVE', 'live', '4K', '8K', 'è¶…æ¸…', 'é«˜æ¸…', 'æ ‡æ¸…', 'é¢‘é“', 'æµ‹è¯•',
        'å˜å½¢é‡‘åˆš', 'å¤ä»‡è€…è”ç›Ÿ', 'é€Ÿåº¦ä¸æ¿€æƒ…', 'ç¢Ÿä¸­è°', 'å“ˆåˆ©æ³¢ç‰¹',
        'æ˜Ÿçƒå¤§æˆ˜', 'ä¾ç½—çºªå…¬å›­', 'æ³°å¦å°¼å…‹å·', 'é˜¿å‡¡è¾¾', 'ç›—æ¢¦ç©ºé—´',
        'è¥¿æ¸¸è®°', 'é¹¿é¼è®°', 'å¯»ç§¦è®°', 'å¤§å”åŒé¾™ä¼ ', 'å¤©é¾™å…«éƒ¨',
        'å°„é›•è‹±é›„ä¼ ', 'ç¥é›•ä¾ ä¾£', 'å€šå¤©å± é¾™è®°', 'ç¬‘å‚²æ±Ÿæ¹–', 'é›ªå±±é£ç‹',
        'ç”„å¬›ä¼ ', 'ç…çŠæ¦œ', 'åº†ä½™å¹´', 'ç‹‚é£™', 'äººæ°‘çš„åä¹‰'
    ],
    'åœ°æ–¹': ['éƒ½å¸‚', 'æ–°é—»', 'ç»¼åˆ', 'å…¬å…±', 'ç”Ÿæ´»', 'å¨±ä¹',
             'å°‘å„¿', 'å¡é€š', 'ä½“è‚²', 'è´¢ç»', 'çºªå®', 'æ•™è‚²', 'æ°‘ç”Ÿ', 'äº¤é€š', 'æ–‡è‰º', 'éŸ³ä¹',
             'æˆæ›²', 'é«˜å°”å¤«', 'ç½‘çƒ']
}

EXCLUDE_IF_HAS = ['ç»¼åˆ', 'æ–°é—»', 'ç”Ÿæ´»', 'å°‘å„¿', 'å…¬å…±', 'äº¤é€š', 'æ–‡è‰º', 'éŸ³ä¹', 'æˆæ›²', 'ä½“è‚²', 'è´¢ç»', 'æ•™è‚²', 'æ°‘ç”Ÿ', 'éƒ½å¸‚']


# ---------------- å›½å¤–è¿‡æ»¤ ----------------
FOREIGN_KEYWORDS = {
    'cnn', 'bbc', 'fox', 'espn', 'disney', 'hbo', 'nat geo', 'national geographic',
    'animal planet', 'mtv', 'paramount', 'pluto tv', 'sky sports', 'eurosport',
    'al jazeera', 'france 24', 'rt', 'nhk', 'kbs', 'tvb', 'abema', 'tokyo',
    'discovery', 'history', 'lifetime', 'syfy', 'tnt', 'usa network',
    'nickelodeon', 'cartoon network', 'boomerang', 'babyfirst', 'first channel',
    'russia', 'germany', 'italy', 'spain', 'france', 'uk', 'united kingdom',
    'canada', 'australia', 'new zealand', 'india', 'pakistan', 'japan', 'south korea'
}

ALLOWED_FOREIGN = {
    'å‡¤å‡°', 'å‡¤å‡°å«è§†', 'å‡¤å‡°ä¸­æ–‡', 'å‡¤å‡°èµ„è®¯', 'ATV', 'äºšæ´²ç”µè§†', 'æ˜Ÿç©º', 'Channel [V]',
    'åå¨±', 'CCTVå¤§å¯Œ', 'CCTV-4', 'CCTV4', 'ä¸­å›½ä¸­å¤®ç”µè§†å°', 'å›½é™…å°', 'CGTN', 'CCTVè¥¿ç­ç‰™è¯­', 'CCTVæ³•è¯­',
    'é¦™æ¸¯', 'æ¾³é—¨', 'å°æ¹¾', 'TVB', 'ç¿¡ç¿ å°', 'æ˜ç å°', 'J2', 'æ— çº¿', 'äºšè§†', 'ATV',
    'ä¸­å¤©', 'ä¸œæ£®', 'ä¸‰ç«‹', 'æ°‘è§†', 'å…¬è§†', 'å°è§†', 'ä¸­è§†'
}


# ================== Utility Functions ==================
def is_foreign_channel(name):
    name_lower = name.lower()
    for allowed in ALLOWED_FOREIGN:
        if allowed in name:
            return False
    for keyword in FOREIGN_KEYWORDS:
        if keyword in name_lower:
            return True
    return False


def is_valid_url(url):
    try:
        result = urlparse(url.strip())
        return all([result.scheme in ('http', 'https'), result.netloc])
    except:
        return False


def normalize_url(url):
    try:
        parsed = urlparse(url.strip().lower())
        if not parsed.scheme or not parsed.netloc:
            return ""
        safe_params = {}
        unsafe_keys = {'token', 't', 'ts', 'sign', 'auth_key', 'verify', 'session', 'key', 'pwd', 'stb', 'icpid', 'RTS', 'from', 'hms_devid', 'online', 'vqe', 'txSecret', 'txTime', 'stat', 'wsSecret', 'wsTime', 'j', 'authid', 'playlive'}
        for k, v_list in parse_qs(parsed.query).items():
            if k.lower() not in unsafe_keys and v_list and v_list[0]:
                safe_params[k] = v_list[0]
        new_query = '&'.join(f"{k}={v}" for k, v in safe_params.items())
        return urlunparse(parsed._replace(query=new_query))
    except Exception:
        return url.lower().split('?')[0]


def merge_and_deduplicate(channels):
    seen = set()
    unique = []
    for item in channels:
        name, url, group = item
        norm_url = normalize_url(url)
        if norm_url and norm_url not in seen:
            seen.add(norm_url)
            unique.append(item)
    print(f"âœ… After dedup: {len(unique)} unique streams")
    return unique


def categorize_channel(name):
    name_lower = name.lower()

    # å¼ºåˆ¶å¤®è§†
    if 'cctv' in name_lower or 'ä¸­å¤®' in name_lower:
        return 'å¤®è§†'

    # åŒ¹é…å«è§†
    for kw in CATEGORY_MAP['å«è§†']:
        if kw.lower() in name_lower:
            return 'å«è§†'

    # åŒ¹é…è½®æ’­ï¼Œä½†æ’é™¤â€œç»¼åˆâ€ç­‰
    for kw in CATEGORY_MAP['è½®æ’­é¢‘é“']:
        if kw.lower() in name_lower:
            if any(ex.lower() in name_lower for ex in EXCLUDE_IF_HAS):
                continue
            return 'è½®æ’­é¢‘é“'

    # åŒ¹é…åœ°æ–¹
    for kw in CATEGORY_MAP['åœ°æ–¹']:
        if kw.lower() in name_lower:
            return 'åœ°æ–¹'

    return "å…¶ä»–"


def check_url_valid(url, timeout=CHECK_TIMEOUT):
    """æ£€æµ‹URLæ˜¯å¦å¯è®¿é—®ï¼ˆç”¨äºå¤®è§†æºï¼‰"""
    try:
        response = requests.head(url, timeout=timeout, headers=DEFAULT_HEADERS, allow_redirects=True)
        return response.status_code < 400
    except:
        try:
            response = requests.get(url, timeout=timeout, headers=DEFAULT_HEADERS, stream=True)
            return response.status_code < 400
        except:
            return False


def load_whitelist():
    """åŠ è½½ç™½åå•ï¼Œç›´æ¥ä½œä¸ºâ€œæœ¬åœ°èŠ‚ç›®â€ï¼Œä¿ç•™åŸå§‹é¡ºåº"""
    print(f"ğŸ‘‰ Loading whitelist: {REMOTE_WHITELIST_URL}")
    try:
        response = requests.get(REMOTE_WHITELIST_URL, timeout=WHITELIST_TIMEOUT)
        response.raise_for_status()
        lines = response.text.strip().splitlines()
        channels = []

        for line in lines:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            parts = [p.strip() for p in line.split(",", 1)]
            if len(parts) < 2:
                continue
            name, url = parts[0], parts[1]
            if not name or not url or not is_valid_url(url):
                continue
            if is_foreign_channel(name):
                print(f"ğŸŒ Skipped foreign (whitelist): {name}")
                continue
            channels.append((name, url, "æœ¬åœ°èŠ‚ç›®"))  # ç›´æ¥åˆ†ç±»
        print(f"âœ… Loaded {len(channels)} from whitelist (as 'æœ¬åœ°èŠ‚ç›®')")
        return channels
    except Exception as e:
        print(f"âŒ Load whitelist failed: {e}")
        return []


def load_tv_m3u():
    print(f"ğŸ‘‰ Loading tv.m3u: {TV_M3U_URL}")
    try:
        response = requests.get(TV_M3U_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        response.raise_for_status()
        lines = response.text.strip().splitlines()
        channels = []
        current_name = None

        for line in lines:
            line = line.strip()
            if line.startswith("#EXTINF"):
                try:
                    name_part = line.split(",", 1)
                    if len(name_part) > 1:
                        current_name = name_part[1].strip()
                except:
                    current_name = "Unknown"
            elif line.startswith("http"):
                if current_name and is_valid_url(line):
                    if is_foreign_channel(current_name):
                        print(f"ğŸŒ Skipped foreign (tv.m3u): {current_name}")
                    else:
                        category = categorize_channel(current_name)
                        channels.append((current_name, line, category))
                current_name = None
        print(f"âœ… Loaded {len(channels)} from tv.m3u")
        return channels
    except Exception as e:
        print(f"âŒ Failed to load tv.m3u: {e}")
        return []


def load_guovin_iptv():
    """åŠ è½½ Guovin çš„ result.txt"""
    print(f"ğŸ‘‰ Loading Guovin IPTV: {GUOVIN_IPTV_URL}")
    try:
        response = requests.get(GUOVIN_IPTV_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        response.raise_for_status()
        response.encoding = 'utf-8'
        lines = response.text.strip().splitlines()
        channels = []
        for line in lines:
            line = line.strip()
            if not line or line.startswith("#") or "," not in line:
                continue
            try:
                name, url = map(str.strip, line.split(",", 1))
                if not name or not url or not is_valid_url(url):
                    continue
                if is_foreign_channel(name):
                    print(f"ğŸŒ Skipped foreign (Guovin): {name}")
                    continue
                category = categorize_channel(name)
                channels.append((name, url, category))
            except Exception as e:
                print(f"âš ï¸ Parse failed: {line} | {e}")
        print(f"âœ… Loaded {len(channels)} from Guovin")
        return channels
    except Exception as e:
        print(f"âŒ Load Guovin failed: {e}")
        return []


def get_dynamic_stream():
    print("ğŸ‘‰ Fetching dynamic stream from API...")
    try:
        response = requests.get(API_URL, params=PARAMS, headers=HEADERS, timeout=10)
        response.raise_for_status()
        data = response.json()
        if 'data' in data and 'm3u8Url' in data['data']:
            url = data['data']['m3u8Url']
            name = "è¥¿å……ç»¼åˆ"
            if is_foreign_channel(name):
                print("ğŸŒ Skipped foreign (API)")
                return None
            print(f"âœ… Dynamic stream added: {name}")
            return (name, url, "æœ¬åœ°èŠ‚ç›®")  # åŠ¨æ€æµä¹Ÿå½’ä¸ºæœ¬åœ°
        else:
            print("âŒ m3u8Url not found in API response")
    except Exception as e:
        print(f"âŒ API request failed: {e}")
    return None


def check_cctv_validity(channels):
    """æ£€æµ‹æ‰€æœ‰å¤®è§†æºæ˜¯å¦æœ‰æ•ˆï¼Œæ— æ•ˆåˆ™è·³è¿‡"""
    print("ğŸ” Checking CCTV stream validity...")
    valid_channels = []
    cctv_count = 0
    for item in channels:
        name, url, group = item
        if group == 'å¤®è§†':
            cctv_count += 1
            if check_url_valid(url):
                valid_channels.append(item)
                print(f"  âœ… Valid: {name}")
            else:
                print(f"  âŒ Invalid: {name}")
        else:
            valid_channels.append(item)
    print(f"âœ… {cctv_count} CCTV streams checked.")
    return valid_channels


def generate_m3u8_content(channels):
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    lines = [
        "#EXTM3U",
        f"# Generated at: {now}",
        "x-tvg-url=\"https://epg.51zmt.top/xmltv.xml\""
    ]

    # è‡ªå®šä¹‰æ’åºæƒé‡
    ORDER = {
        'æœ¬åœ°èŠ‚ç›®': 0,
        'å¤®è§†': 1,
        'å«è§†': 2,
        'è½®æ’­é¢‘é“': 3,
        'å…¶ä»–': 4,
        'åœ°æ–¹': 5
    }

    def sort_key(item):
        group = item[2]
        order = ORDER.get(group, 99)
        return (order, group, item[0])  # æŒ‰ç»„æ’åºï¼Œç»„å†…æŒ‰åç§°æ’åº

    sorted_channels = sorted(channels, key=sort_key)

    for name, url, group in sorted_channels:
        lines.append(f'#EXTINF:-1 tvg-name="{name}" group-title="{group}",{name}')
        lines.append(url)

    return "\n".join(lines) + "\n"


def print_stats(channels):
    stats = Counter(item[2] for item in channels)
    print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡ï¼š")
    for cat, cnt in stats.most_common():
        print(f"   {cat:<10} : {cnt}")
    print(f"   {'æ€»è®¡':<10} : {sum(stats.values())}")


def main():
    print("ğŸš€ Starting playlist generation...")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    all_channels = []

    # === 1. åŠ è½½ç™½åå•ï¼ˆæœ¬åœ°èŠ‚ç›®ï¼Œä¿ç•™é¡ºåºï¼‰===
    whitelist_channels = load_whitelist()
    all_channels.extend(whitelist_channels)

    # === 2. åŠ¨æ€æµï¼ˆä¹Ÿå½’ä¸ºæœ¬åœ°ï¼‰===
    dynamic_item = get_dynamic_stream()
    if dynamic_item:
        all_channels.append(dynamic_item)

    # === 3. å…¶ä»–æº ===
    all_channels.extend(load_tv_m3u())
    all_channels.extend(load_guovin_iptv())

    print(f"ğŸ“¥ Total raw streams: {len(all_channels)}")

    # å»é‡
    unique_channels = merge_and_deduplicate(all_channels)

    # è¿‡æ»¤å›½å¤–
    filtered_channels = [item for item in unique_channels if not is_foreign_channel(item[0])]

    # æ£€æµ‹å¤®è§†æœ‰æ•ˆæ€§
    final_channels = check_cctv_validity(filtered_channels)

    print(f"âœ… Final playlist size: {len(final_channels)} channels")

    print_stats(final_channels)

    m3u8_content = generate_m3u8_content(final_channels)

    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(m3u8_content)
        print(f"ğŸ‰ Successfully generated: {OUTPUT_FILE}")
    except Exception as e:
        print(f"âŒ Write failed: {e}")
        return

    if not os.path.exists('.nojekyll'):
        open('.nojekyll', 'w').close()
        print("ğŸ“„ Created .nojekyll")

    print("âœ… All tasks completed!")


if __name__ == "__main__":
    main()
