# File: get_live_stream.py
# Description: å®Œå…¨æŒ‰ä½ æŒ‡å®šçš„åˆ†ç±»ä¸æ’åºè§„åˆ™ç”Ÿæˆç›´æ’­æºï¼Œå¹¶æ ‡å‡†åŒ– CCTV é¢‘é“å
# Author: Assistant
# Date: 2025-11-06

import requests
import os
from urllib.parse import unquote, urlparse, parse_qs, urlunparse
from datetime import datetime
from collections import Counter, defaultdict
import time
import re

# ================== Configuration ==================
API_URL = "https://lwydapi.xichongtv.cn/a/appLive/info/35137_b14710553f9b43349f46d33cc2b7fcfd"
PARAMS = {
    'deviceType': '1',
    'centerId': '9',
    'deviceToken': 'beb09666-78c0-4ae8-94e9-b0b4180a31be',
    'latitudeValue': '0',
    'areaId': '907',
    'appCenterId': '907',
    'isTest': '0',
    'longitudeValue': '0',
    'deviceVersionType': 'android',
    'versionCodeGlobal': '5009037'
}
HEADERS = {
    'User-Agent': 'okhttp/3.12.12',
}

# --- æºåœ°å€æ›´æ–° ---
REMOTE_WHITELIST_URL = "https://raw.githubusercontent.com/xichongguo/live-stream/main/whitelist.txt"
TV_M3U_URL = "https://raw.githubusercontent.com/wwb521/live/refs/heads/main/tv.m3u"
GUOVIN_IPTV_URL = "https://cdn.jsdelivr.net/gh/Guovin/iptv-api@gd/output/result.txt"

WHITELIST_TIMEOUT = 15
CHECK_TIMEOUT = 5
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

OUTPUT_DIR = "live"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "current.m3u8")


# ---------------- çœä»½æ˜ å°„è¡¨ ----------------
PROVINCE_KEYWORDS = {
    'å››å·': ['å››å·', 'æˆéƒ½', 'ç»µé˜³', 'å¾·é˜³', 'å—å……', 'å®œå®¾', 'æ³¸å·', 'ä¹å±±', 'è¾¾å·', 'å†…æ±Ÿ', 'è‡ªè´¡', 'æ”€æèŠ±', 'å¹¿å®‰', 'é‚å®', 'èµ„é˜³', 'çœ‰å±±', 'é›…å®‰', 'å·´ä¸­', 'é˜¿å', 'ç”˜å­œ', 'å‡‰å±±'],
    'å¹¿ä¸œ': ['å¹¿ä¸œ', 'å¹¿å·', 'æ·±åœ³', 'ä½›å±±', 'ä¸œè', 'ä¸­å±±', 'ç æµ·', 'æƒ å·', 'æ±Ÿé—¨', 'è‚‡åº†', 'æ±•å¤´', 'æ½®å·', 'æ­é˜³', 'æ±•å°¾', 'æ¹›æ±Ÿ', 'èŒ‚å', 'é˜³æ±Ÿ', 'äº‘æµ®', 'æ¸…è¿œ', 'éŸ¶å…³', 'æ²³æº'],
    'æ¹–å—': ['æ¹–å—', 'é•¿æ²™', 'æ ªæ´²', 'æ¹˜æ½­', 'è¡¡é˜³', 'é‚µé˜³', 'å²³é˜³', 'å¸¸å¾·', 'å¼ å®¶ç•Œ', 'ç›Šé˜³', 'éƒ´å·', 'æ°¸å·', 'æ€€åŒ–', 'å¨„åº•', 'æ¹˜è¥¿'],
    'æ¹–åŒ—': ['æ¹–åŒ—', 'æ­¦æ±‰', 'é»„çŸ³', 'åå °', 'å®œæ˜Œ', 'è¥„é˜³', 'é„‚å·', 'è†é—¨', 'å­æ„Ÿ', 'è†å·', 'é»„å†ˆ', 'å’¸å®', 'éšå·', 'æ©æ–½'],
    'æ±Ÿè‹': ['æ±Ÿè‹', 'å—äº¬', 'æ— é”¡', 'å¾å·', 'å¸¸å·', 'è‹å·', 'å—é€š', 'è¿äº‘æ¸¯', 'æ·®å®‰', 'ç›åŸ', 'æ‰¬å·', 'é•‡æ±Ÿ', 'æ³°å·', 'å®¿è¿'],
    'æµ™æ±Ÿ': ['æµ™æ±Ÿ', 'æ­å·', 'å®æ³¢', 'æ¸©å·', 'å˜‰å…´', 'æ¹–å·', 'ç»å…´', 'é‡‘å', 'è¡¢å·', 'èˆŸå±±', 'å°å·', 'ä¸½æ°´'],
    'å±±ä¸œ': ['å±±ä¸œ', 'æµå—', 'é’å²›', 'æ·„åš', 'æ£åº„', 'ä¸œè¥', 'çƒŸå°', 'æ½åŠ', 'æµå®', 'æ³°å®‰', 'å¨æµ·', 'æ—¥ç…§', 'ä¸´æ²‚', 'å¾·å·', 'èŠåŸ', 'æ»¨å·', 'èæ³½'],
    'æ²³å—': ['æ²³å—', 'éƒ‘å·', 'å¼€å°', 'æ´›é˜³', 'å¹³é¡¶å±±', 'å®‰é˜³', 'é¹¤å£', 'æ–°ä¹¡', 'ç„¦ä½œ', 'æ¿®é˜³', 'è®¸æ˜Œ', 'æ¼¯æ²³', 'ä¸‰é—¨å³¡', 'å—é˜³', 'å•†ä¸˜', 'ä¿¡é˜³', 'å‘¨å£', 'é©»é©¬åº—'],
    'æ²³åŒ—': ['æ²³åŒ—', 'çŸ³å®¶åº„', 'å”å±±', 'ç§¦çš‡å²›', 'é‚¯éƒ¸', 'é‚¢å°', 'ä¿å®š', 'å¼ å®¶å£', 'æ‰¿å¾·', 'æ²§å·', 'å»ŠåŠ', 'è¡¡æ°´'],
    'ç¦å»º': ['ç¦å»º', 'ç¦å·', 'å¦é—¨', 'è†ç”°', 'ä¸‰æ˜', 'æ³‰å·', 'æ¼³å·', 'å—å¹³', 'é¾™å²©', 'å®å¾·'],
    'å¹¿è¥¿': ['å¹¿è¥¿', 'å—å®', 'æŸ³å·', 'æ¡‚æ—', 'æ¢§å·', 'åŒ—æµ·', 'é˜²åŸæ¸¯', 'é’¦å·', 'è´µæ¸¯', 'ç‰æ—', 'ç™¾è‰²', 'è´ºå·', 'æ²³æ± ', 'æ¥å®¾', 'å´‡å·¦'],
    'äº‘å—': ['äº‘å—', 'æ˜†æ˜', 'æ›²é–', 'ç‰æºª', 'ä¿å±±', 'æ˜­é€š', 'ä¸½æ±Ÿ', 'æ™®æ´±', 'ä¸´æ²§', 'æ¥šé›„', 'çº¢æ²³', 'æ–‡å±±', 'è¥¿åŒç‰ˆçº³', 'å¤§ç†', 'å¾·å®', 'æ€’æ±Ÿ', 'è¿ªåº†'],
    'æ±Ÿè¥¿': ['æ±Ÿè¥¿', 'å—æ˜Œ', 'æ™¯å¾·é•‡', 'èä¹¡', 'ä¹æ±Ÿ', 'æ–°ä½™', 'é¹°æ½­', 'èµ£å·', 'å‰å®‰', 'å®œæ˜¥', 'æŠšå·', 'ä¸Šé¥¶'],
    'è¾½å®': ['è¾½å®', 'æ²ˆé˜³', 'å¤§è¿', 'éå±±', 'æŠšé¡º', 'æœ¬æºª', 'ä¸¹ä¸œ', 'é”¦å·', 'è¥å£', 'é˜œæ–°', 'è¾½é˜³', 'ç›˜é”¦', 'é“å²­', 'æœé˜³', 'è‘«èŠ¦å²›'],
    'å±±è¥¿': ['å±±è¥¿', 'å¤ªåŸ', 'å¤§åŒ', 'é˜³æ³‰', 'é•¿æ²»', 'æ™‹åŸ', 'æœ”å·', 'æ™‹ä¸­', 'è¿åŸ', 'å¿»å·', 'ä¸´æ±¾', 'å•æ¢'],
    'é™•è¥¿': ['é™•è¥¿', 'è¥¿å®‰', 'é“œå·', 'å®é¸¡', 'å’¸é˜³', 'æ¸­å—', 'å»¶å®‰', 'æ±‰ä¸­', 'æ¦†æ—', 'å®‰åº·', 'å•†æ´›'],
    'å®‰å¾½': ['å®‰å¾½', 'åˆè‚¥', 'èŠœæ¹–', 'èšŒåŸ ', 'æ·®å—', 'é©¬éå±±', 'æ·®åŒ—', 'é“œé™µ', 'å®‰åº†', 'é»„å±±', 'æ»å·', 'é˜œé˜³', 'å®¿å·', 'å…­å®‰', 'äº³å·', 'æ± å·', 'å®£åŸ'],
    'é»‘é¾™æ±Ÿ': ['é»‘é¾™æ±Ÿ', 'å“ˆå°”æ»¨', 'é½é½å“ˆå°”', 'é¸¡è¥¿', 'é¹¤å²—', 'åŒé¸­å±±', 'å¤§åº†', 'ä¼Šæ˜¥', 'ä½³æœ¨æ–¯', 'ä¸ƒå°æ²³', 'ç‰¡ä¸¹æ±Ÿ', 'é»‘æ²³', 'ç»¥åŒ–'],
    'å†…è’™å¤': ['å†…è’™å¤', 'å‘¼å’Œæµ©ç‰¹', 'åŒ…å¤´', 'ä¹Œæµ·', 'èµ¤å³°', 'é€šè¾½', 'é„‚å°”å¤šæ–¯', 'å‘¼ä¼¦è´å°”', 'å·´å½¦æ·–å°”', 'ä¹Œå…°å¯Ÿå¸ƒ', 'å…´å®‰', 'é”¡æ—éƒ­å‹’', 'é˜¿æ‹‰å–„'],
    'å‰æ—': ['å‰æ—', 'é•¿æ˜¥', 'å‰æ—å¸‚', 'å››å¹³', 'è¾½æº', 'é€šåŒ–', 'ç™½å±±', 'æ¾åŸ', 'ç™½åŸ', 'å»¶è¾¹'],
    'è´µå·': ['è´µå·', 'è´µé˜³', 'å…­ç›˜æ°´', 'éµä¹‰', 'å®‰é¡º', 'æ¯•èŠ‚', 'é“œä»', 'é»”è¥¿å—', 'é»”ä¸œå—', 'é»”å—'],
    'ç”˜è‚ƒ': ['ç”˜è‚ƒ', 'å…°å·', 'å˜‰å³ªå…³', 'é‡‘æ˜Œ', 'ç™½é“¶', 'å¤©æ°´', 'æ­¦å¨', 'å¼ æ–', 'å¹³å‡‰', 'é…’æ³‰', 'åº†é˜³', 'å®šè¥¿', 'é™‡å—', 'ä¸´å¤', 'ç”˜å—'],
    'æµ·å—': ['æµ·å—', 'æµ·å£', 'ä¸‰äºš', 'ä¸‰æ²™', 'å„‹å·', 'äº”æŒ‡å±±', 'ç¼æµ·', 'æ–‡æ˜Œ', 'ä¸‡å®', 'ä¸œæ–¹', 'å®šå®‰', 'å±¯æ˜Œ', 'æ¾„è¿ˆ', 'ä¸´é«˜', 'ç™½æ²™', 'æ˜Œæ±Ÿ', 'ä¹ä¸œ', 'é™µæ°´', 'ä¿äº­', 'ç¼ä¸­'],
    'é’æµ·': ['é’æµ·', 'è¥¿å®', 'æµ·ä¸œ', 'æµ·åŒ—', 'é»„å—', 'æµ·å—', 'æœæ´›', 'ç‰æ ‘', 'æµ·è¥¿'],
    'å®å¤': ['å®å¤', 'é“¶å·', 'çŸ³å˜´å±±', 'å´å¿ ', 'å›ºåŸ', 'ä¸­å«'],
    'æ–°ç–†': ['æ–°ç–†', 'ä¹Œé²æœ¨é½', 'å…‹æ‹‰ç›ä¾', 'åé²ç•ª', 'å“ˆå¯†', 'æ˜Œå‰', 'åšå°”å¡”æ‹‰', 'å·´éŸ³éƒ­æ¥', 'é˜¿å…‹è‹', 'å…‹å­œå‹’è‹', 'å–€ä»€', 'å’Œç”°', 'ä¼ŠçŠ', 'å¡”åŸ', 'é˜¿å‹’æ³°'],
    'è¥¿è—': ['è¥¿è—', 'æ‹‰è¨', 'æ—¥å–€åˆ™', 'æ˜Œéƒ½', 'æ—èŠ', 'å±±å—', 'é‚£æ›²', 'é˜¿é‡Œ']
}

# åå‘æ˜ å°„ï¼šåŸå¸‚ â†’ çœä»½
CITY_TO_PROVINCE = {city: prov for prov, cities in PROVINCE_KEYWORDS.items() for city in cities}


# ---------------- åˆ†ç±»è§„åˆ™ ----------------
CATEGORY_MAP = {
    'å¤®è§†': ['cctv', 'ä¸­å¤®'],
    'å«è§†': ['å«è§†', 'æ¹–å—', 'æµ™æ±Ÿ', 'æ±Ÿè‹', 'ä¸œæ–¹', 'åŒ—äº¬', 'å¹¿ä¸œ', 'æ·±åœ³', 'å››å·', 'æ¹–åŒ—', 'è¾½å®',
             'ä¸œå—', 'å¤©æ´¥', 'é‡åº†', 'é»‘é¾™æ±Ÿ', 'å±±ä¸œ', 'å®‰å¾½', 'äº‘å—', 'é™•è¥¿', 'ç”˜è‚ƒ', 'æ–°ç–†',
             'å†…è’™å¤', 'å‰æ—', 'æ²³åŒ—', 'å±±è¥¿', 'å¹¿è¥¿', 'æ±Ÿè¥¿', 'ç¦å»º', 'è´µå·', 'æµ·å—'],
    'ç”µå½±é¢‘é“': ['ç”µå½±', 'å½±é™¢', 'å½±è§†', 'ç²¾é€‰', 'ç»å…¸', 'å¤§ç‰‡', 'çƒ­æ’­', 'å‰§åœº', 'è™ç‰™', 'æ–—é±¼', 'LIVE', 'live', '4K', '8K'],
    'æ¸¯æ¾³å°': ['é¦™æ¸¯', 'æ¾³é—¨', 'å°æ¹¾', 'TVB', 'ç¿¡ç¿ å°', 'æ˜ç å°', 'J2', 'æ— çº¿', 'äºšè§†', 'ATV', 'å‡¤å‡°', 'ä¸­å¤©', 'ä¸œæ£®', 'ä¸‰ç«‹', 'æ°‘è§†', 'å…¬è§†', 'å°è§†', 'ä¸­è§†'],
    'ç»å…¸å‰§åœº': ['è¥¿æ¸¸è®°', 'é¹¿é¼è®°', 'å¯»ç§¦è®°', 'å¤§å”åŒé¾™ä¼ ', 'å¤©é¾™å…«éƒ¨', 'å°„é›•è‹±é›„ä¼ ', 'ç¥é›•ä¾ ä¾£', 'å€šå¤©å± é¾™è®°', 'ç¬‘å‚²æ±Ÿæ¹–', 'é›ªå±±é£ç‹', 'ç”„å¬›ä¼ ', 'ç…çŠæ¦œ', 'åº†ä½™å¹´', 'ç‹‚é£™', 'äººæ°‘çš„åä¹‰']
}

EXCLUDE_IF_HAS = ['ç»¼åˆ', 'æ–°é—»', 'ç”Ÿæ´»', 'å°‘å„¿', 'å…¬å…±', 'äº¤é€š', 'æ–‡è‰º', 'éŸ³ä¹', 'æˆæ›²', 'ä½“è‚²', 'è´¢ç»', 'æ•™è‚²', 'æ°‘ç”Ÿ', 'éƒ½å¸‚', 'è½®æ’­', 'å›çœ‹', 'é‡æ¸©']


# ---------------- å›½å¤–è¿‡æ»¤ ----------------
FOREIGN_KEYWORDS = {
    'cnn', 'bbc', 'fox', 'espn', 'disney', 'hbo', 'nat geo', 'national geographic',
    'animal planet', 'mtv', 'paramount', 'pluto tv', 'sky sports', 'eurosport',
    'al jazeera', 'france 24', 'rt', 'nhk', 'kbs', 'abema', 'tokyo',
    'discovery', 'history', 'lifetime', 'syfy', 'tnt', 'usa network',
    'nickelodeon', 'cartoon network', 'boomerang', 'babyfirst', 'first channel',
    'russia', 'germany', 'italy', 'spain', 'france', 'uk', 'united kingdom',
    'canada', 'australia', 'new zealand', 'india', 'pakistan', 'japan', 'south korea'
}

ALLOWED_FOREIGN = {
    'å‡¤å‡°', 'å‡¤å‡°å«è§†', 'å‡¤å‡°ä¸­æ–‡', 'å‡¤å‡°èµ„è®¯', 'ATV', 'äºšæ´²ç”µè§†', 'æ˜Ÿç©º', 'åå¨±',
    'CCTVå¤§å¯Œ', 'CCTV-4', 'CCTV4', 'ä¸­å›½ä¸­å¤®ç”µè§†å°', 'å›½é™…å°', 'CGTN', 'CCTVè¥¿ç­ç‰™è¯­', 'CCTVæ³•è¯­',
    'é¦™æ¸¯', 'æ¾³é—¨', 'å°æ¹¾', 'TVB', 'ç¿¡ç¿ å°', 'æ˜ç å°', 'J2', 'æ— çº¿', 'äºšè§†', 'ATV',
    'ä¸­å¤©', 'ä¸œæ£®', 'ä¸‰ç«‹', 'æ°‘è§†', 'å…¬è§†', 'å°è§†', 'ä¸­è§†'
}


# ================== æ–°å¢ï¼šCCTV æ ‡å‡†åŒ– ==================
def normalize_cctv_name(name):
    """
    å°†å„ç§å½¢å¼çš„ CCTV åç§°æ ‡å‡†åŒ–ä¸º 'CCTV-N'ï¼ˆN æ— å‰å¯¼é›¶ï¼‰
    æ”¯æŒè‹±æ–‡å˜ä½“å’Œä¸­æ–‡åˆ«å
    """
    name = name.strip()
    if not name:
        return name

    # ä¸­æ–‡åˆ«åæ˜ å°„
    CHINESE_ALIAS = {
        "ä¸­å¤®ä¸€å¥—": "CCTV-1",
        "ç»¼åˆé¢‘é“": "CCTV-1",
        "ä¸­å¤®äºŒå¥—": "CCTV-2",
        "è´¢ç»é¢‘é“": "CCTV-2",
        "ä¸­å¤®ä¸‰å¥—": "CCTV-3",
        "ç»¼è‰ºé¢‘é“": "CCTV-3",
        "ä¸­å¤®å››å¥—": "CCTV-4",
        "ä¸­æ–‡å›½é™…é¢‘é“": "CCTV-4",
        "ä¸­å¤®äº”å¥—": "CCTV-5",
        "ä½“è‚²é¢‘é“": "CCTV-5",
        "ä¸­å¤®å…­å¥—": "CCTV-6",
        "ç”µå½±é¢‘é“": "CCTV-6",
        "ä¸­å¤®ä¸ƒå¥—": "CCTV-7",
        "å›½é˜²å†›äº‹é¢‘é“": "CCTV-7",
        "ä¸­å¤®å…«å¥—": "CCTV-8",
        "ç”µè§†å‰§é¢‘é“": "CCTV-8",
        "ä¸­å¤®ä¹å¥—": "CCTV-9",
        "çºªå½•é¢‘é“": "CCTV-9",
        "ä¸­å¤®åå¥—": "CCTV-10",
        "ç§‘æ•™é¢‘é“": "CCTV-10",
        "ä¸­å¤®åä¸€å¥—": "CCTV-11",
        "æˆæ›²é¢‘é“": "CCTV-11",
        "ä¸­å¤®åäºŒå¥—": "CCTV-12",
        "ç¤¾ä¼šä¸æ³•é¢‘é“": "CCTV-12",
        "ä¸­å¤®åä¸‰å¥—": "CCTV-13",
        "æ–°é—»é¢‘é“": "CCTV-13",
        "ä¸­å¤®åå››å¥—": "CCTV-14",
        "å°‘å„¿é¢‘é“": "CCTV-14",
        "ä¸­å¤®åäº”å¥—": "CCTV-15",
        "éŸ³ä¹é¢‘é“": "CCTV-15",
        "ä¸­å¤®åä¸ƒå¥—": "CCTV-17",
        "å†œä¸šå†œæ‘é¢‘é“": "CCTV-17",
    }

    # 1. ç²¾ç¡®åŒ¹é…ä¸­æ–‡åˆ«å
    if name in CHINESE_ALIAS:
        return CHINESE_ALIAS[name]

    # 2. æ¨¡ç³ŠåŒ¹é…å…³é”®è¯
    for keyword, std in CHINESE_ALIAS.items():
        if keyword in name:
            return std

    # 3. åŒ¹é…è‹±æ–‡æ ¼å¼
    name_upper = name.upper()
    match = re.search(r'CCTV\D*(\d+)', name_upper)
    if match:
        number = str(int(match.group(1)))
        return f"CCTV-{number}"

    return name  # æ— æ³•è¯†åˆ«åˆ™åŸæ ·è¿”å›


# ================== Utility Functions ==================
def is_foreign_channel(name):
    name_lower = name.lower()
    for allowed in ALLOWED_FOREIGN:
        if allowed in name:
            return False
    for keyword in FOREIGN_KEYWORDS:
        if keyword in name_lower:
            return True
    return False


def is_valid_url(url):
    try:
        result = urlparse(url.strip())
        return all([result.scheme in ('http', 'https'), result.netloc])
    except:
        return False


def normalize_url(url):
    try:
        parsed = urlparse(url.strip().lower())
        if not parsed.scheme or not parsed.netloc:
            return ""
        safe_params = {}
        unsafe_keys = {'token', 't', 'ts', 'sign', 'auth_key', 'verify', 'session', 'key', 'pwd', 'stb', 'icpid', 'RTS', 'from', 'hms_devid', 'online', 'vqe', 'txSecret', 'txTime', 'stat', 'wsSecret', 'wsTime', 'j', 'authid', 'playlive'}
        for k, v_list in parse_qs(parsed.query).items():
            if k.lower() not in unsafe_keys and v_list and v_list[0]:
                safe_params[k] = v_list[0]
        new_query = '&'.join(f"{k}={v}" for k, v in safe_params.items())
        return urlunparse(parsed._replace(query=new_query))
    except Exception:
        return url.lower().split('?')[0]


def merge_and_deduplicate(channels):
    seen = set()
    unique = []
    for item in channels:
        name, url, group = item
        norm_url = normalize_url(url)
        if norm_url and norm_url not in seen:
            seen.add(norm_url)
            unique.append(item)
    print(f"âœ… After dedup: {len(unique)} unique streams")
    return unique


def categorize_channel(name):
    name_lower = name.lower()

    # å¤®è§†
    if any(kw in name_lower for kw in ['cctv', 'ä¸­å¤®']):
        # æ ‡å‡†åŒ–åç§°
        std_name = normalize_cctv_name(name)
        return 'å¤®è§†', std_name

    # å«è§†
    for kw in CATEGORY_MAP['å«è§†']:
        if kw.lower() in name_lower:
            return 'å«è§†', name

    # ç”µå½±é¢‘é“
    for kw in CATEGORY_MAP['ç”µå½±é¢‘é“']:
        if kw.lower() in name_lower:
            if any(ex.lower() in name_lower for ex in EXCLUDE_IF_HAS):
                continue
            return 'ç”µå½±é¢‘é“', name

    # æ¸¯æ¾³å°
    for kw in CATEGORY_MAP['æ¸¯æ¾³å°']:
        if kw in name:
            return 'æ¸¯æ¾³å°', name

    # ç»å…¸å‰§åœº
    for kw in CATEGORY_MAP['ç»å…¸å‰§åœº']:
        if kw in name:
            return 'ç»å…¸å‰§åœº', name

    # çœä»½
    for prov, cities in PROVINCE_KEYWORDS.items():
        for city in cities:
            if city in name:
                return prov, name

    return "å…¶ä»–", name


def check_url_valid(url, timeout=CHECK_TIMEOUT):
    """æ£€æµ‹URLæ˜¯å¦å¯è®¿é—®ï¼ˆç”¨äºå¤®è§†æºï¼‰"""
    try:
        response = requests.head(url, timeout=timeout, headers=DEFAULT_HEADERS, allow_redirects=True)
        return response.status_code < 400
    except:
        try:
            response = requests.get(url, timeout=timeout, headers=DEFAULT_HEADERS, stream=True)
            return response.status_code < 400
        except:
            return False


def load_whitelist():
    """åŠ è½½ç™½åå•ï¼Œä½œä¸ºâ€œæœ¬åœ°èŠ‚ç›®â€ï¼Œä¿ç•™åŸå§‹é¡ºåº"""
    print(f"ğŸ‘‰ Loading whitelist: {REMOTE_WHITELIST_URL}")
    try:
        response = requests.get(REMOTE_WHITELIST_URL, timeout=WHITELIST_TIMEOUT)
        response.raise_for_status()
        lines = response.text.strip().splitlines()
        channels = []

        for line in lines:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            parts = [p.strip() for p in line.split(",", 1)]
            if len(parts) < 2:
                continue
            name, url = parts[0], parts[1]
            if not name or not url or not is_valid_url(url):
                continue
            if is_foreign_channel(name):
                print(f"ğŸŒ Skipped foreign (whitelist): {name}")
                continue
            channels.append((name, url, "æœ¬åœ°èŠ‚ç›®"))
        print(f"âœ… Loaded {len(channels)} from whitelist (as 'æœ¬åœ°èŠ‚ç›®')")
        return channels
    except Exception as e:
        print(f"âŒ Load whitelist failed: {e}")
        return []


def load_tv_m3u():
    print(f"ğŸ‘‰ Loading tv.m3u: {TV_M3U_URL}")
    try:
        response = requests.get(TV_M3U_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        response.raise_for_status()
        lines = response.text.strip().splitlines()
        channels = []
        current_name = None

        for line in lines:
            line = line.strip()
            if line.startswith("#EXTINF"):
                try:
                    name_part = line.split(",", 1)
                    if len(name_part) > 1:
                        current_name = name_part[1].strip()
                except:
                    current_name = "Unknown"
            elif line.startswith("http"):
                if current_name and is_valid_url(line):
                    if is_foreign_channel(current_name):
                        print(f"ğŸŒ Skipped foreign (tv.m3u): {current_name}")
                    else:
                        category, display_name = categorize_channel(current_name)
                        channels.append((display_name, line, category))
                current_name = None
        print(f"âœ… Loaded {len(channels)} from tv.m3u")
        return channels
    except Exception as e:
        print(f"âŒ Failed to load tv.m3u: {e}")
        return []


def load_guovin_iptv():
    """åŠ è½½ Guovin çš„ result.txt"""
    print(f"ğŸ‘‰ Loading Guovin IPTV: {GUOVIN_IPTV_URL}")
    try:
        response = requests.get(GUOVIN_IPTV_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        response.raise_for_status()
        response.encoding = 'utf-8'
        lines = response.text.strip().splitlines()
        channels = []
        for line in lines:
            line = line.strip()
            if not line or line.startswith("#") or "," not in line:
                continue
            try:
                name, url = map(str.strip, line.split(",", 1))
                if not name or not url or not is_valid_url(url):
                    continue
                if is_foreign_channel(name):
                    print(f"ğŸŒ Skipped foreign (Guovin): {name}")
                    continue
                category, display_name = categorize_channel(name)
                channels.append((display_name, url, category))
            except Exception as e:
                print(f"âš ï¸ Parse failed: {line} | {e}")
        print(f"âœ… Loaded {len(channels)} from Guovin")
        return channels
    except Exception as e:
        print(f"âŒ Load Guovin failed: {e}")
        return []


def get_dynamic_stream():
    print("ğŸ‘‰ Fetching dynamic stream from API...")
    try:
        response = requests.get(API_URL, params=PARAMS, headers=HEADERS, timeout=10)
        response.raise_for_status()
        data = response.json()
        if 'data' in data and 'm3u8Url' in data['data']:
            url = data['data']['m3u8Url']
            name = "è¥¿å……ç»¼åˆ"
            if is_foreign_channel(name):
                print("ğŸŒ Skipped foreign (API)")
                return None
            print(f"âœ… Dynamic stream added: {name}")
            return (name, url, "æœ¬åœ°èŠ‚ç›®")
        else:
            print("âŒ m3u8Url not found in API response")
    except Exception as e:
        print(f"âŒ API request failed: {e}")
    return None


def check_cctv_validity(channels):
    """æ£€æµ‹æ‰€æœ‰å¤®è§†æºæ˜¯å¦æœ‰æ•ˆï¼Œæ— æ•ˆåˆ™è·³è¿‡"""
    print("ğŸ” Checking CCTV stream validity...")
    valid_channels = []
    cctv_count = 0
    for item in channels:
        name, url, group = item
        if group == 'å¤®è§†':
            cctv_count += 1
            if check_url_valid(url):
                valid_channels.append(item)
                print(f"  âœ… Valid: {name}")
            else:
                print(f"  âŒ Invalid: {name}")
        else:
            valid_channels.append(item)
    print(f"âœ… {cctv_count} CCTV streams checked.")
    return valid_channels


def sort_channels(channels):
    """è‡ªå®šä¹‰æ’åº"""
    ORDER = [
        'æœ¬åœ°èŠ‚ç›®', 'å¤®è§†', 'å«è§†',
        'å››å·', 'å¹¿ä¸œ', 'æ¹–å—', 'æ¹–åŒ—', 'æ±Ÿè‹', 'æµ™æ±Ÿ', 'å±±ä¸œ', 'æ²³å—', 'æ²³åŒ—', 'ç¦å»º', 'å¹¿è¥¿', 'äº‘å—', 'æ±Ÿè¥¿', 'è¾½å®', 'å±±è¥¿', 'é™•è¥¿', 'å®‰å¾½', 'é»‘é¾™æ±Ÿ', 'å†…è’™å¤', 'å‰æ—', 'è´µå·', 'ç”˜è‚ƒ', 'æµ·å—', 'é’æµ·', 'å®å¤', 'æ–°ç–†', 'è¥¿è—',
        'ç”µå½±é¢‘é“', 'æ¸¯æ¾³å°', 'ç»å…¸å‰§åœº'
    ]

    LOCAL_PRIORITY = {
        "è¥¿å……ç»¼åˆ": 0,
        "å—å……ç»¼åˆ": 1,
        "å—å……ç§‘æ•™ç”Ÿæ´»": 2
    }

    def get_cctv_number(name):
        match = re.search(r'CCTV-(\d+)', name)
        return int(match.group(1)) if match else float('inf')

    def sort_key(item):
        name, url, group = item

        if group == 'æœ¬åœ°èŠ‚ç›®':
            if name in LOCAL_PRIORITY:
                return (ORDER.index(group), LOCAL_PRIORITY[name], name)
            else:
                return (ORDER.index(group), 999, name)

        elif group == 'å¤®è§†':
            # å¤®è§†å†…éƒ¨æŒ‰æ•°å­—æ’åº
            num = get_cctv_number(name)
            return (ORDER.index(group), num, name)

        else:
            group_order = ORDER.index(group) if group in ORDER else 999
            return (group_order, name)

    return sorted(channels, key=sort_key)


def generate_m3u8_content(channels):
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    lines = [
        "#EXTM3U",
        f"# Generated at: {now}",
        "x-tvg-url=\"https://epg.51zmt.top/xmltv.xml\""
    ]

    sorted_channels = sort_channels(channels)

    for name, url, group in sorted_channels:
        lines.append(f'#EXTINF:-1 tvg-name="{name}" group-title="{group}",{name}')
        lines.append(url)

    return "\n".join(lines) + "\n"


def print_stats(channels):
    stats = Counter(item[2] for item in channels)
    print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡ï¼š")
    for cat, cnt in stats.most_common():
        print(f"   {cat:<10} : {cnt}")
    print(f"   {'æ€»è®¡':<10} : {sum(stats.values())}")


def main():
    print("ğŸš€ Starting playlist generation...")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    all_channels = []

    # === 1. åŠ è½½ç™½åå•ï¼ˆæœ¬åœ°èŠ‚ç›®ï¼‰===
    whitelist_channels = load_whitelist()
    all_channels.extend(whitelist_channels)

    # === 2. åŠ¨æ€æµï¼ˆä¹Ÿå½’ä¸ºæœ¬åœ°ï¼‰===
    dynamic_item = get_dynamic_stream()
    if dynamic_item:
        all_channels.append(dynamic_item)

    # === 3. å…¶ä»–æº ===
    all_channels.extend(load_tv_m3u())
    all_channels.extend(load_guovin_iptv())

    print(f"ğŸ“¥ Total raw streams: {len(all_channels)}")

    # å»é‡
    unique_channels = merge_and_deduplicate(all_channels)

    # è¿‡æ»¤å›½å¤–
    filtered_channels = [item for item in unique_channels if not is_foreign_channel(item[0])]

    # æ£€æµ‹å¤®è§†æœ‰æ•ˆæ€§
    final_channels = check_cctv_validity(filtered_channels)

    print(f"âœ… Final playlist size: {len(final_channels)} channels")

    print_stats(final_channels)

    m3u8_content = generate_m3u8_content(final_channels)

    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(m3u8_content)
        print(f"ğŸ‰ Successfully generated: {OUTPUT_FILE}")
    except Exception as e:
        print(f"âŒ Write failed: {e}")
        return

    if not os.path.exists('.nojekyll'):
        open('.nojekyll', 'w').close()
        print("ğŸ“„ Created .nojekyll")

    print("âœ… All tasks completed!")


if __name__ == "__main__":
    main()
