# File: get_live_stream.py (Updated for "keep all, sort by source")
# Author: Assistant
# Date: 2025-11-16

import requests
import os
from urllib.parse import unquote, urlparse, parse_qs, urlunparse
from datetime import datetime
from collections import Counter, defaultdict
import time
import re

# ================== Configuration ==================
API_URL = "https://lwydapi.xichongtv.cn/a/appLive/info/35137_b14710553f9b43349f46d33cc2b7fcfd"
PARAMS = {
    'deviceType': '1',
    'centerId': '9',
    'deviceToken': 'beb09666-78c0-4ae8-94e9-b0b4180a31be',
    'latitudeValue': '0',
    'areaId': '907',
    'appCenterId': '907',
    'isTest': '0',
    'longitudeValue': '0',
    'deviceVersionType': 'android',
    'versionCodeGlobal': '5009037'
}
HEADERS = {
    'User-Agent': 'okhttp/3.12.12',
}

REMOTE_WHITELIST_URL = "https://raw.githubusercontent.com/xichongguo/live-stream/main/whitelist.txt"
TV_M3U_URL = "https://raw.githubusercontent.com/wwb521/live/refs/heads/main/tv.m3u"
GUOVIN_IPTV_URL = "https://cdn.jsdelivr.net/gh/Guovin/iptv-api@gd/output/result.txt"
BC_API_URL = "https://bc.188766.xyz/"
BC_PARAMS = {'ip': '', 'mima': 'bingchawusifengxian', 'json': 'true'}

LOCAL_TXT_PATH = "local.txt"

WHITELIST_TIMEOUT = 15
CHECK_TIMEOUT = 5
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

OUTPUT_DIR = "live"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "current.m3u8")

# æ¥æºä¼˜å…ˆçº§ï¼šæ•°å€¼è¶Šå°ï¼Œæ’åºè¶Šé å‰ï¼ˆä½†ä¸å»é‡ï¼ï¼‰
PRIORITY_LOCAL_TXT = 0      # æœ€é å‰
PRIORITY_WHITELIST = 1
PRIORITY_DYNAMIC = 1
PRIORITY_OTHER = 1          # æ‰€æœ‰é local éƒ½æ˜¯ 1

# çœä»½æ˜ å°„ã€åˆ†ç±»è§„åˆ™ã€å›½å¤–è¿‡æ»¤ç­‰ï¼ˆä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼‰
# â¬‡ï¸ ä»¥ä¸‹ä¸ºç®€åŒ–ç‰ˆï¼Œå®é™…ä½¿ç”¨è¯·ä¿ç•™å®Œæ•´æ˜ å°„è¡¨ï¼ˆè§ä¸Šä¸€ç‰ˆæœ¬ï¼‰
PROVINCE_KEYWORDS = { ... }  # è¯·ä»ä¸Šä¸€ç‰ˆæœ¬å¤åˆ¶å®Œæ•´å†…å®¹
CITY_TO_PROVINCE = {city: prov for prov, cities in PROVINCE_KEYWORDS.items() for city in cities}

CATEGORY_MAP = { ... }  # è¯·ä»ä¸Šä¸€ç‰ˆæœ¬å¤åˆ¶
EXCLUDE_IF_HAS = [...]     # è¯·ä»ä¸Šä¸€ç‰ˆæœ¬å¤åˆ¶
FOREIGN_KEYWORDS = {...}   # è¯·ä»ä¸Šä¸€ç‰ˆæœ¬å¤åˆ¶
ALLOWED_FOREIGN = {...}    # è¯·ä»ä¸Šä¸€ç‰ˆæœ¬å¤åˆ¶


def is_foreign_channel(name):
    name_lower = name.lower()
    for allowed in ALLOWED_FOREIGN:
        if allowed in name:
            return False
    for keyword in FOREIGN_KEYWORDS:
        if keyword in name_lower:
            return True
    return False

def is_valid_url(url):
    try:
        result = urlparse(url.strip())
        return all([result.scheme in ('http', 'https'), result.netloc])
    except:
        return False

def normalize_cctv_name(name):
    CHINESE_ALIAS = {
        "ä¸­å¤®ä¸€å¥—": "CCTV-1", "ç»¼åˆé¢‘é“": "CCTV-1",
        "ä¸­å¤®äºŒå¥—": "CCTV-2", "è´¢ç»é¢‘é“": "CCTV-2",
        "ä¸­å¤®ä¸‰å¥—": "CCTV-3", "ç»¼è‰ºé¢‘é“": "CCTV-3",
        "ä¸­å¤®å››å¥—": "CCTV-4", "ä¸­æ–‡å›½é™…é¢‘é“": "CCTV-4",
        "ä¸­å¤®äº”å¥—": "CCTV-5", "ä½“è‚²é¢‘é“": "CCTV-5",
        "ä¸­å¤®å…­å¥—": "CCTV-6", "ç”µå½±é¢‘é“": "CCTV-6",
        "ä¸­å¤®ä¸ƒå¥—": "CCTV-7", "å›½é˜²å†›äº‹é¢‘é“": "CCTV-7",
        "ä¸­å¤®å…«å¥—": "CCTV-8", "ç”µè§†å‰§é¢‘é“": "CCTV-8",
        "ä¸­å¤®ä¹å¥—": "CCTV-9", "çºªå½•é¢‘é“": "CCTV-9",
        "ä¸­å¤®åå¥—": "CCTV-10", "ç§‘æ•™é¢‘é“": "CCTV-10",
        "ä¸­å¤®åä¸€å¥—": "CCTV-11", "æˆæ›²é¢‘é“": "CCTV-11",
        "ä¸­å¤®åäºŒå¥—": "CCTV-12", "ç¤¾ä¼šä¸æ³•é¢‘é“": "CCTV-12",
        "ä¸­å¤®åä¸‰å¥—": "CCTV-13", "æ–°é—»é¢‘é“": "CCTV-13",
        "ä¸­å¤®åå››å¥—": "CCTV-14", "å°‘å„¿é¢‘é“": "CCTV-14",
        "ä¸­å¤®åäº”å¥—": "CCTV-15", "éŸ³ä¹é¢‘é“": "CCTV-15",
        "ä¸­å¤®åä¸ƒå¥—": "CCTV-17", "å†œä¸šå†œæ‘é¢‘é“": "CCTV-17",
    }
    if name in CHINESE_ALIAS:
        return CHINESE_ALIAS[name]
    for keyword, std in CHINESE_ALIAS.items():
        if keyword in name:
            return std
    match = re.search(r'CCTV\D*(\d+)', name.upper())
    if match:
        return f"CCTV-{int(match.group(1))}"
    return name

def categorize_channel(name):
    name_lower = name.lower()
    if any(kw in name_lower for kw in ['cctv', 'ä¸­å¤®']):
        return 'å¤®è§†', normalize_cctv_name(name)
    for kw in CATEGORY_MAP['å«è§†']:
        if kw.lower() in name_lower:
            return 'å«è§†', name
    for kw in CATEGORY_MAP['ç”µå½±é¢‘é“']:
        if kw.lower() in name_lower and not any(ex.lower() in name_lower for ex in EXCLUDE_IF_HAS):
            return 'ç”µå½±é¢‘é“', name
    for kw in CATEGORY_MAP['æ¸¯æ¾³å°']:
        if kw in name:
            return 'æ¸¯æ¾³å°', name
    for kw in CATEGORY_MAP['ç»å…¸å‰§åœº']:
        if kw in name:
            return 'ç»å…¸å‰§åœº', name
    for prov, cities in PROVINCE_KEYWORDS.items():
        for city in cities:
            if city in name:
                return prov, name
    return "å…¶ä»–", name

def check_url_valid(url, timeout=CHECK_TIMEOUT):
    try:
        response = requests.head(url, timeout=timeout, headers=DEFAULT_HEADERS, allow_redirects=True)
        return response.status_code < 400
    except:
        try:
            response = requests.get(url, timeout=timeout, headers=DEFAULT_HEADERS, stream=True)
            return response.status_code < 400
        except:
            return False

# ========== åŠ è½½å‡½æ•°ï¼ˆå…¨éƒ¨è¿”å›å››å…ƒç»„ï¼‰==========
def load_whitelist():
    print(f"ğŸ‘‰ Loading whitelist...")
    try:
        response = requests.get(REMOTE_WHITELIST_URL, timeout=WHITELIST_TIMEOUT)
        lines = response.text.strip().splitlines()
        channels = []
        for line in lines:
            line = line.strip()
            if not line or line.startswith("#"): continue
            parts = [p.strip() for p in line.split(",", 1)]
            if len(parts) < 2: continue
            name, url = parts[0], parts[1]
            if not name or not url or not is_valid_url(url): continue
            if is_foreign_channel(name): continue
            channels.append((name, url, "æœ¬åœ°èŠ‚ç›®", PRIORITY_WHITELIST))
        return channels
    except Exception as e:
        print(f"âŒ Load whitelist failed: {e}")
        return []

def get_dynamic_stream():
    try:
        response = requests.get(API_URL, params=PARAMS, headers=HEADERS, timeout=10)
        data = response.json()
        if 'data' in data and 'm3u8Url' in data['data']:
            name, url = "è¥¿å……ç»¼åˆ", data['data']['m3u8Url']
            if not is_foreign_channel(name):
                return (name, url, "æœ¬åœ°èŠ‚ç›®", PRIORITY_DYNAMIC)
    except:
        pass
    return None

def load_tv_m3u():
    try:
        response = requests.get(TV_M3U_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        lines = response.text.strip().splitlines()
        channels = []
        current_name = None
        for line in lines:
            if line.startswith("#EXTINF"):
                current_name = line.split(",", 1)[1].strip() if "," in line else "Unknown"
            elif line.startswith("http") and current_name:
                if is_valid_url(line) and not is_foreign_channel(current_name):
                    cat, disp = categorize_channel(current_name)
                    channels.append((disp, line, cat, PRIORITY_OTHER))
                current_name = None
        return channels
    except Exception as e:
        print(f"âŒ Load tv.m3u failed: {e}")
        return []

def load_guovin_iptv():
    try:
        response = requests.get(GUOVIN_IPTV_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        response.encoding = 'utf-8'
        lines = response.text.strip().splitlines()
        channels = []
        for line in lines:
            if line.strip().startswith("#") or "," not in line: continue
            name, url = map(str.strip, line.split(",", 1))
            if is_valid_url(url) and not is_foreign_channel(name):
                cat, disp = categorize_channel(name)
                channels.append((disp, url, cat, PRIORITY_OTHER))
        return channels
    except Exception as e:
        print(f"âŒ Load Guovin failed: {e}")
        return []

def load_bc_api():
    try:
        response = requests.get(BC_API_URL, params=BC_PARAMS, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        data = response.json()
        channels = []
        for item in data.get("data", []):
            name = str(item.get("name", "")).strip()
            url = str(item.get("url", "")).strip()
            if name and url and is_valid_url(url) and not is_foreign_channel(name):
                cat, disp = categorize_channel(name)
                channels.append((disp, url, cat, PRIORITY_OTHER))
        return channels
    except Exception as e:
        print(f"âŒ Load BC API failed: {e}")
        return []

def load_local_txt():
    if not os.path.exists(LOCAL_TXT_PATH):
        return []
    channels = []
    try:
        with open(LOCAL_TXT_PATH, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        for line in lines:
            line = line.strip()
            if not line or line.startswith("#"): continue
            parts = [p.strip() for p in line.split(",", 1)]
            if len(parts) < 2: continue
            name, url = parts[0], parts[1]
            if not name or not url or not is_valid_url(url): continue
            if is_foreign_channel(name): continue
            cat, disp = categorize_channel(name)
            channels.append((disp, url, cat, PRIORITY_LOCAL_TXT))
    except Exception as e:
        print(f"âŒ Read local.txt failed: {e}")
    return channels

# ========== å…³é”®ï¼šæ’åºï¼ˆä¸å»é‡ï¼ï¼‰==========
def sort_channels_with_priority(channels):
    ORDER = [
        'æœ¬åœ°èŠ‚ç›®', 'å¤®è§†', 'å«è§†',
        'å››å·', 'å¹¿ä¸œ', 'æ¹–å—', 'æ¹–åŒ—', 'æ±Ÿè‹', 'æµ™æ±Ÿ', 'å±±ä¸œ', 'æ²³å—', 'æ²³åŒ—', 'ç¦å»º', 'å¹¿è¥¿', 'äº‘å—', 'æ±Ÿè¥¿', 'è¾½å®', 'å±±è¥¿', 'é™•è¥¿', 'å®‰å¾½', 'é»‘é¾™æ±Ÿ', 'å†…è’™å¤', 'å‰æ—', 'è´µå·', 'ç”˜è‚ƒ', 'æµ·å—', 'é’æµ·', 'å®å¤', 'æ–°ç–†', 'è¥¿è—',
        'ç”µå½±é¢‘é“', 'æ¸¯æ¾³å°', 'ç»å…¸å‰§åœº'
    ]

    LOCAL_PRIORITY = {"è¥¿å……ç»¼åˆ": 0, "å—å……ç»¼åˆ": 1, "å—å……ç§‘æ•™ç”Ÿæ´»": 2}

    def get_cctv_number(name):
        match = re.search(r'CCTV-(\d+)', name)
        return int(match.group(1)) if match else float('inf')

    def sort_key(item):
        name, url, group, priority = item
        group_order = ORDER.index(group) if group in ORDER else 999

        if group == 'æœ¬åœ°èŠ‚ç›®':
            local_order = LOCAL_PRIORITY.get(name, 999)
            return (priority, group_order, local_order, name)
        elif group == 'å¤®è§†':
            return (priority, group_order, get_cctv_number(name), name)
        else:
            return (priority, group_order, name)

    return sorted(channels, key=sort_key)

# ========== ä¸»æµç¨‹ ==========
def main():
    print("ğŸš€ Starting playlist generation (keep all, sort by source)...")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    all_channels = []

    # åŠ è½½æ‰€æœ‰æºï¼ˆå…¨éƒ¨ä¿ç•™ï¼‰
    all_channels.extend(load_whitelist())
    dynamic = get_dynamic_stream()
    if dynamic: all_channels.append(dynamic)
    all_channels.extend(load_tv_m3u())
    all_channels.extend(load_guovin_iptv())
    all_channels.extend(load_bc_api())
    all_channels.extend(load_local_txt())  # è¿™äº›ä¼šè¢«æ’åˆ°æœ€å‰

    # è¿‡æ»¤å›½å¤–ï¼ˆäºŒæ¬¡ä¿é™©ï¼‰
    filtered = [item for item in all_channels if not is_foreign_channel(item[0])]

    # æ£€æµ‹å¤®è§†æœ‰æ•ˆæ€§ï¼ˆå¯é€‰ï¼šä½ ä¹Ÿå¯ä»¥è·³è¿‡è¿™æ­¥ä»¥ä¿ç•™æ›´å¤šæºï¼‰
    valid_channels = []
    for item in filtered:
        name, url, group, priority = item
        if group == 'å¤®è§†':
            if check_url_valid(url):
                valid_channels.append(item)
            else:
                print(f"âŒ Skipped invalid CCTV: {name}")
        else:
            valid_channels.append(item)

    # æ’åºï¼šlocal.txt ä¼˜å…ˆ
    sorted_channels = sort_channels_with_priority(valid_channels)

    # ç»Ÿè®¡
    stats = Counter(item[2] for item in sorted_channels)
    print(f"\nğŸ“Š Total channels: {len(sorted_channels)}")
    for cat, cnt in stats.most_common():
        print(f"   {cat:<10}: {cnt}")

    # ç”Ÿæˆ M3U8ï¼ˆåªå–å‰ä¸‰å­—æ®µï¼‰
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    lines = ["#EXTM3U", f"# Generated at: {now}", 'x-tvg-url="https://epg.51zmt.top/xmltv.xml"']
    for name, url, group, _ in sorted_channels:
        lines.append(f'#EXTINF:-1 tvg-name="{name}" group-title="{group}",{name}')
        lines.append(url)

    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines) + "\n")
        print(f"ğŸ‰ Output written to: {OUTPUT_FILE}")
    except Exception as e:
        print(f"âŒ Write error: {e}")

    if not os.path.exists('.nojekyll'):
        open('.nojekyll', 'w').close()

if __name__ == "__main__":
    main()
