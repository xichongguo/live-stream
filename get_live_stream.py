# File: get_live_stream.py
# Final update: 
#   - whitelist.txt â†’ "æœ¬åœ°èŠ‚ç›®" (top, priority=0)
#   - tv.m3u â†’ priority=1 (next)
#   - other remotes â†’ priority=2
#   - local.txt â†’ priority=3 (last, no validation)
#   - dedup by (name, group), keep first

import requests
import os
from urllib.parse import urlparse
from datetime import datetime
from collections import Counter
import re

# ================== Configuration ==================
API_URL = "https://lwydapi.xichongtv.cn/a/appLive/info/35137_b14710553f9b43349f46d33cc2b7fcfd"
PARAMS = {
    'deviceType': '1',
    'centerId': '9',
    'deviceToken': 'beb09666-78c0-4ae8-94e9-b0b4180a31be',
    'latitudeValue': '0',
    'areaId': '907',
    'appCenterId': '907',
    'isTest': '0',
    'longitudeValue': '0',
    'deviceVersionType': 'android',
    'versionCodeGlobal': '5009037'
}
HEADERS = {
    'User-Agent': 'okhttp/3.12.12',
}

REMOTE_WHITELIST_URL = "https://raw.githubusercontent.com/xichongguo/live-stream/main/whitelist.txt"
GUOVIN_IPTV_URL = "https://cdn.jsdelivr.net/gh/Guovin/iptv-api@gd/output/result.txt"
TV_M3U_URL = "https://raw.githubusercontent.com/wwb521/live/refs/heads/main/tv.m3u"
BC_API_URL = "https://bc.188766.xyz/"
BC_PARAMS = {'ip': '', 'mima': 'bingchawusifengxian', 'json': 'true'}

LOCAL_TXT_PATH = "local.txt"

WHITELIST_TIMEOUT = 15
CHECK_TIMEOUT = 5
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

OUTPUT_DIR = "live"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "current.m3u8")

# ---------------- çœä»½æ˜ å°„è¡¨ ----------------
PROVINCE_KEYWORDS = {
    'å››å·': ['å››å·', 'æˆéƒ½', 'ç»µé˜³', 'å¾·é˜³', 'å—å……', 'å®œå®¾', 'æ³¸å·', 'ä¹å±±', 'è¾¾å·', 'å†…æ±Ÿ', 'è‡ªè´¡', 'æ”€æèŠ±', 'å¹¿å®‰', 'é‚å®', 'èµ„é˜³', 'çœ‰å±±', 'é›…å®‰', 'å·´ä¸­', 'é˜¿å', 'ç”˜å­œ', 'å‡‰å±±'],
    'å¹¿ä¸œ': ['å¹¿ä¸œ', 'å¹¿å·', 'æ·±åœ³', 'ä½›å±±', 'ä¸œè', 'ä¸­å±±', 'ç æµ·', 'æƒ å·', 'æ±Ÿé—¨', 'è‚‡åº†', 'æ±•å¤´', 'æ½®å·', 'æ­é˜³', 'æ±•å°¾', 'æ¹›æ±Ÿ', 'èŒ‚å', 'é˜³æ±Ÿ', 'äº‘æµ®', 'æ¸…è¿œ', 'éŸ¶å…³', 'æ²³æº'],
    'æ¹–å—': ['æ¹–å—', 'é•¿æ²™', 'æ ªæ´²', 'æ¹˜æ½­', 'è¡¡é˜³', 'é‚µé˜³', 'å²³é˜³', 'å¸¸å¾·', 'å¼ å®¶ç•Œ', 'ç›Šé˜³', 'éƒ´å·', 'æ°¸å·', 'æ€€åŒ–', 'å¨„åº•', 'æ¹˜è¥¿'],
    'æ¹–åŒ—': ['æ¹–åŒ—', 'æ­¦æ±‰', 'é»„çŸ³', 'åå °', 'å®œæ˜Œ', 'è¥„é˜³', 'é„‚å·', 'è†é—¨', 'å­æ„Ÿ', 'è†å·', 'é»„å†ˆ', 'å’¸å®', 'éšå·', 'æ©æ–½'],
    'æ±Ÿè‹': ['æ±Ÿè‹', 'å—äº¬', 'æ— é”¡', 'å¾å·', 'å¸¸å·', 'è‹å·', 'å—é€š', 'è¿äº‘æ¸¯', 'æ·®å®‰', 'ç›åŸ', 'æ‰¬å·', 'é•‡æ±Ÿ', 'æ³°å·', 'å®¿è¿'],
    'æµ™æ±Ÿ': ['æµ™æ±Ÿ', 'æ­å·', 'å®æ³¢', 'æ¸©å·', 'å˜‰å…´', 'æ¹–å·', 'ç»å…´', 'é‡‘å', 'è¡¢å·', 'èˆŸå±±', 'å°å·', 'ä¸½æ°´'],
    'å±±ä¸œ': ['å±±ä¸œ', 'æµå—', 'é’å²›', 'æ·„åš', 'æ£åº„', 'ä¸œè¥', 'çƒŸå°', 'æ½åŠ', 'æµå®', 'æ³°å®‰', 'å¨æµ·', 'æ—¥ç…§', 'ä¸´æ²‚', 'å¾·å·', 'èŠåŸ', 'æ»¨å·', 'èæ³½'],
    'æ²³å—': ['æ²³å—', 'éƒ‘å·', 'å¼€å°', 'æ´›é˜³', 'å¹³é¡¶å±±', 'å®‰é˜³', 'é¹¤å£', 'æ–°ä¹¡', 'ç„¦ä½œ', 'æ¿®é˜³', 'è®¸æ˜Œ', 'æ¼¯æ²³', 'ä¸‰é—¨å³¡', 'å—é˜³', 'å•†ä¸˜', 'ä¿¡é˜³', 'å‘¨å£', 'é©»é©¬åº—'],
    'æ²³åŒ—': ['æ²³åŒ—', 'çŸ³å®¶åº„', 'å”å±±', 'ç§¦çš‡å²›', 'é‚¯éƒ¸', 'é‚¢å°', 'ä¿å®š', 'å¼ å®¶å£', 'æ‰¿å¾·', 'æ²§å·', 'å»ŠåŠ', 'è¡¡æ°´'],
    'ç¦å»º': ['ç¦å»º', 'ç¦å·', 'å¦é—¨', 'è†ç”°', 'ä¸‰æ˜', 'æ³‰å·', 'æ¼³å·', 'å—å¹³', 'é¾™å²©', 'å®å¾·'],
    'å¹¿è¥¿': ['å¹¿è¥¿', 'å—å®', 'æŸ³å·', 'æ¡‚æ—', 'æ¢§å·', 'åŒ—æµ·', 'é˜²åŸæ¸¯', 'é’¦å·', 'è´µæ¸¯', 'ç‰æ—', 'ç™¾è‰²', 'è´ºå·', 'æ²³æ± ', 'æ¥å®¾', 'å´‡å·¦'],
    'äº‘å—': ['äº‘å—', 'æ˜†æ˜', 'æ›²é–', 'ç‰æºª', 'ä¿å±±', 'æ˜­é€š', 'ä¸½æ±Ÿ', 'æ™®æ´±', 'ä¸´æ²§', 'æ¥šé›„', 'çº¢æ²³', 'æ–‡å±±', 'è¥¿åŒç‰ˆçº³', 'å¤§ç†', 'å¾·å®', 'æ€’æ±Ÿ', 'è¿ªåº†'],
    'æ±Ÿè¥¿': ['æ±Ÿè¥¿', 'å—æ˜Œ', 'æ™¯å¾·é•‡', 'èä¹¡', 'ä¹æ±Ÿ', 'æ–°ä½™', 'é¹°æ½­', 'èµ£å·', 'å‰å®‰', 'å®œæ˜¥', 'æŠšå·', 'ä¸Šé¥¶'],
    'è¾½å®': ['è¾½å®', 'æ²ˆé˜³', 'å¤§è¿', 'éå±±', 'æŠšé¡º', 'æœ¬æºª', 'ä¸¹ä¸œ', 'é”¦å·', 'è¥å£', 'é˜œæ–°', 'è¾½é˜³', 'ç›˜é”¦', 'é“å²­', 'æœé˜³', 'è‘«èŠ¦å²›'],
    'å±±è¥¿': ['å±±è¥¿', 'å¤ªåŸ', 'å¤§åŒ', 'é˜³æ³‰', 'é•¿æ²»', 'æ™‹åŸ', 'æœ”å·', 'æ™‹ä¸­', 'è¿åŸ', 'å¿»å·', 'ä¸´æ±¾', 'å•æ¢'],
    'é™•è¥¿': ['é™•è¥¿', 'è¥¿å®‰', 'é“œå·', 'å®é¸¡', 'å’¸é˜³', 'æ¸­å—', 'å»¶å®‰', 'æ±‰ä¸­', 'æ¦†æ—', 'å®‰åº·', 'å•†æ´›'],
    'å®‰å¾½': ['å®‰å¾½', 'åˆè‚¥', 'èŠœæ¹–', 'èšŒåŸ ', 'æ·®å—', 'é©¬éå±±', 'æ·®åŒ—', 'é“œé™µ', 'å®‰åº†', 'é»„å±±', 'æ»å·', 'é˜œé˜³', 'å®¿å·', 'å…­å®‰', 'äº³å·', 'æ± å·', 'å®£åŸ'],
    'é»‘é¾™æ±Ÿ': ['é»‘é¾™æ±Ÿ', 'å“ˆå°”æ»¨', 'é½é½å“ˆå°”', 'é¸¡è¥¿', 'é¹¤å²—', 'åŒé¸­å±±', 'å¤§åº†', 'ä¼Šæ˜¥', 'ä½³æœ¨æ–¯', 'ä¸ƒå°æ²³', 'ç‰¡ä¸¹æ±Ÿ', 'é»‘æ²³', 'ç»¥åŒ–'],
    'å†…è’™å¤': ['å†…è’™å¤', 'å‘¼å’Œæµ©ç‰¹', 'åŒ…å¤´', 'ä¹Œæµ·', 'èµ¤å³°', 'é€šè¾½', 'é„‚å°”å¤šæ–¯', 'å‘¼ä¼¦è´å°”', 'å·´å½¦æ·–å°”', 'ä¹Œå…°å¯Ÿå¸ƒ', 'å…´å®‰', 'é”¡æ—éƒ­å‹’', 'é˜¿æ‹‰å–„'],
    'å‰æ—': ['å‰æ—', 'é•¿æ˜¥', 'å‰æ—å¸‚', 'å››å¹³', 'è¾½æº', 'é€šåŒ–', 'ç™½å±±', 'æ¾åŸ', 'ç™½åŸ', 'å»¶è¾¹'],
    'è´µå·': ['è´µå·', 'è´µé˜³', 'å…­ç›˜æ°´', 'éµä¹‰', 'å®‰é¡º', 'æ¯•èŠ‚', 'é“œä»', 'é»”è¥¿å—', 'é»”ä¸œå—', 'é»”å—'],
    'ç”˜è‚ƒ': ['ç”˜è‚ƒ', 'å…°å·', 'å˜‰å³ªå…³', 'é‡‘æ˜Œ', 'ç™½é“¶', 'å¤©æ°´', 'æ­¦å¨', 'å¼ æ–', 'å¹³å‡‰', 'é…’æ³‰', 'åº†é˜³', 'å®šè¥¿', 'é™‡å—', 'ä¸´å¤', 'ç”˜å—'],
    'æµ·å—': ['æµ·å—', 'æµ·å£', 'ä¸‰äºš', 'ä¸‰æ²™', 'å„‹å·', 'äº”æŒ‡å±±', 'ç¼æµ·', 'æ–‡æ˜Œ', 'ä¸‡å®', 'ä¸œæ–¹', 'å®šå®‰', 'å±¯æ˜Œ', 'æ¾„è¿ˆ', 'ä¸´é«˜', 'ç™½æ²™', 'æ˜Œæ±Ÿ', 'ä¹ä¸œ', 'é™µæ°´', 'ä¿äº­', 'ç¼ä¸­'],
    'é’æµ·': ['é’æµ·', 'è¥¿å®', 'æµ·ä¸œ', 'æµ·åŒ—', 'é»„å—', 'æµ·å—', 'æœæ´›', 'ç‰æ ‘', 'æµ·è¥¿'],
    'å®å¤': ['å®å¤', 'é“¶å·', 'çŸ³å˜´å±±', 'å´å¿ ', 'å›ºåŸ', 'ä¸­å«'],
    'æ–°ç–†': ['æ–°ç–†', 'ä¹Œé²æœ¨é½', 'å…‹æ‹‰ç›ä¾', 'åé²ç•ª', 'å“ˆå¯†', 'æ˜Œå‰', 'åšå°”å¡”æ‹‰', 'å·´éŸ³éƒ­æ¥', 'é˜¿å…‹è‹', 'å…‹å­œå‹’è‹', 'å–€ä»€', 'å’Œç”°', 'ä¼ŠçŠ', 'å¡”åŸ', 'é˜¿å‹’æ³°'],
    'è¥¿è—': ['è¥¿è—', 'æ‹‰è¨', 'æ—¥å–€åˆ™', 'æ˜Œéƒ½', 'æ—èŠ', 'å±±å—', 'é‚£æ›²', 'é˜¿é‡Œ']
}

CATEGORY_MAP = {
    'å«è§†': ['å«è§†', 'å«æ˜Ÿ', 'ä¸œæ–¹', 'åŒ—äº¬å«è§†', 'å¤©æ´¥å«è§†', 'æ²³åŒ—å«è§†', 'å±±è¥¿å«è§†', 'å†…è’™å¤å«è§†',
             'è¾½å®å«è§†', 'å‰æ—å«è§†', 'é»‘é¾™æ±Ÿå«è§†', 'æ±Ÿè‹å«è§†', 'æµ™æ±Ÿå«è§†', 'å®‰å¾½å«è§†', 'ç¦å»ºä¸œå—',
             'æ±Ÿè¥¿å«è§†', 'å±±ä¸œå«è§†', 'æ²³å—å«è§†', 'æ¹–åŒ—å«è§†', 'æ¹–å—å«è§†', 'å¹¿ä¸œå«è§†', 'å¹¿è¥¿å«è§†',
             'æµ·å—å«è§†', 'å››å·å«è§†', 'é‡åº†å«è§†', 'è´µå·å«è§†', 'äº‘å—å«è§†', 'è¥¿è—å«è§†', 'é™•è¥¿å«è§†',
             'ç”˜è‚ƒå«è§†', 'é’æµ·å«è§†', 'å®å¤å«è§†', 'æ–°ç–†å«è§†'],
    'ç”µå½±é¢‘é“': ['ç”µå½±', 'å½±é™¢', 'CHC', 'åæ•°', 'ä¼˜é…·', 'çˆ±å¥‡è‰º', 'è…¾è®¯', 'èŠ’æœ'],
    'æ¸¯æ¾³å°': ['å‡¤å‡°', 'TVB', 'ç¿¡ç¿ ', 'æ˜ç ', 'J2', 'HOY', 'ä¸œæ£®', 'ä¸­å¤©', 'å¹´ä»£', 'ä¸‰ç«‹', 'æ°‘è§†', 'å…¬è§†', 'åè§†', 'TVBS'],
    'ç»å…¸å‰§åœº': ['ç»å…¸', 'æ€€æ—§', 'è€ç”µå½±', 'æˆæ›²', 'äº¬å‰§']
}

EXCLUDE_IF_HAS = ['å°‘å„¿', 'å¡é€š', 'åŠ¨æ¼«', 'æ¸¸æˆ', 'è´­ç‰©', 'è½®æ’­']

FOREIGN_KEYWORDS = {
    'CNN', 'BBC', 'NHK', 'KBS', 'MBC', 'SBS', 'Arirang', 'France', 'Deutsch', 'RTL', 'Sky', 'Al Jazeera',
    'HBO', 'ESPN', 'Star Sports', 'Fox', 'Discovery', 'National Geographic', 'Cartoon Network',
    'Nickelodeon', 'MTV', 'VH1', 'CNBC', 'Bloomberg', 'DW', 'RT', 'CGTN', 'ABS-CBN', 'GMA', 'TV5'
}

ALLOWED_FOREIGN = {'å‡¤å‡°', 'TVB', 'ç¿¡ç¿ ', 'æ˜ç ', 'ä¸œæ£®', 'ä¸­å¤©', 'å¹´ä»£', 'ä¸‰ç«‹', 'æ°‘è§†', 'å…¬è§†', 'åè§†', 'TVBS'}


# ================== Helper Functions ==================
def is_foreign_channel(name):
    name_lower = name.lower()
    for allowed in ALLOWED_FOREIGN:
        if allowed in name:
            return False
    for keyword in FOREIGN_KEYWORDS:
        if keyword.lower() in name_lower:
            return True
    return False

def is_valid_url(url):
    try:
        result = urlparse(url.strip())
        return all([result.scheme in ('http', 'https'), result.netloc])
    except:
        return False

def normalize_cctv_name(name):
    CHINESE_ALIAS = {
        "ä¸­å¤®ä¸€å¥—": "CCTV-1", "ç»¼åˆé¢‘é“": "CCTV-1",
        "ä¸­å¤®äºŒå¥—": "CCTV-2", "è´¢ç»é¢‘é“": "CCTV-2",
        "ä¸­å¤®ä¸‰å¥—": "CCTV-3", "ç»¼è‰ºé¢‘é“": "CCTV-3",
        "ä¸­å¤®å››å¥—": "CCTV-4", "ä¸­æ–‡å›½é™…é¢‘é“": "CCTV-4",
        "ä¸­å¤®äº”å¥—": "CCTV-5", "ä½“è‚²é¢‘é“": "CCTV-5",
        "ä¸­å¤®å…­å¥—": "CCTV-6", "ç”µå½±é¢‘é“": "CCTV-6",
        "ä¸­å¤®ä¸ƒå¥—": "CCTV-7", "å›½é˜²å†›äº‹é¢‘é“": "CCTV-7",
        "ä¸­å¤®å…«å¥—": "CCTV-8", "ç”µè§†å‰§é¢‘é“": "CCTV-8",
        "ä¸­å¤®ä¹å¥—": "CCTV-9", "çºªå½•é¢‘é“": "CCTV-9",
        "ä¸­å¤®åå¥—": "CCTV-10", "ç§‘æ•™é¢‘é“": "CCTV-10",
        "ä¸­å¤®åä¸€å¥—": "CCTV-11", "æˆæ›²é¢‘é“": "CCTV-11",
        "ä¸­å¤®åäºŒå¥—": "CCTV-12", "ç¤¾ä¼šä¸æ³•é¢‘é“": "CCTV-12",
        "ä¸­å¤®åä¸‰å¥—": "CCTV-13", "æ–°é—»é¢‘é“": "CCTV-13",
        "ä¸­å¤®åå››å¥—": "CCTV-14", "å°‘å„¿é¢‘é“": "CCTV-14",
        "ä¸­å¤®åäº”å¥—": "CCTV-15", "éŸ³ä¹é¢‘é“": "CCTV-15",
        "ä¸­å¤®åä¸ƒå¥—": "CCTV-17", "å†œä¸šå†œæ‘é¢‘é“": "CCTV-17",
    }
    if name in CHINESE_ALIAS:
        return CHINESE_ALIAS[name]
    for keyword, std in CHINESE_ALIAS.items():
        if keyword in name:
            return std
    match = re.search(r'CCTV\D*(\d+)', name.upper())
    if match:
        return f"CCTV-{int(match.group(1))}"
    return name

def categorize_channel(name):
    name_lower = name.lower()
    if any(kw in name_lower for kw in ['cctv', 'ä¸­å¤®']):
        return 'å¤®è§†', normalize_cctv_name(name)
    for kw in CATEGORY_MAP['å«è§†']:
        if kw.lower() in name_lower:
            return 'å«è§†', name
    for kw in CATEGORY_MAP['ç”µå½±é¢‘é“']:
        if kw.lower() in name_lower and not any(ex.lower() in name_lower for ex in EXCLUDE_IF_HAS):
            return 'ç”µå½±é¢‘é“', name
    for kw in CATEGORY_MAP['æ¸¯æ¾³å°']:
        if kw in name:
            return 'æ¸¯æ¾³å°', name
    for kw in CATEGORY_MAP['ç»å…¸å‰§åœº']:
        if kw in name:
            return 'ç»å…¸å‰§åœº', name
    for prov, cities in PROVINCE_KEYWORDS.items():
        for city in cities:
            if city in name:
                return prov, name
    return "å…¶ä»–", name

def check_url_valid(url, timeout=CHECK_TIMEOUT):
    try:
        response = requests.head(url, timeout=timeout, headers=DEFAULT_HEADERS, allow_redirects=True)
        return response.status_code < 400
    except:
        try:
            response = requests.get(url, timeout=timeout, headers=DEFAULT_HEADERS, stream=True)
            return response.status_code < 400
        except:
            return False


# ================== Load Sources ==================
def load_whitelist_as_local_program():
    print(f"ğŸ‘‰ Loading whitelist.txt as 'æœ¬åœ°èŠ‚ç›®' (TOP, priority=0)...")
    try:
        response = requests.get(REMOTE_WHITELIST_URL, timeout=WHITELIST_TIMEOUT)
        lines = response.text.strip().splitlines()
        channels = []
        for line in lines:
            line = line.strip()
            if not line or line.startswith("#"): continue
            parts = [p.strip() for p in line.split(",", 1)]
            if len(parts) < 2: continue
            name, url = parts[0], parts[1]
            if not name or not url or not is_valid_url(url): continue
            if is_foreign_channel(name): continue
            channels.append((name, url, "æœ¬åœ°èŠ‚ç›®", 0))
        return channels
    except Exception as e:
        print(f"âŒ Load whitelist.txt failed: {e}")
        return []

def get_dynamic_stream():
    try:
        response = requests.get(API_URL, params=PARAMS, headers=HEADERS, timeout=10)
        data = response.json()
        if 'data' in data and 'm3u8Url' in data['data']:
            name, url = "è¥¿å……ç»¼åˆ", data['data']['m3u8Url']
            if not is_foreign_channel(name):
                cat, disp = categorize_channel(name)
                return (disp, url, cat, 2)
    except:
        pass
    return None

def load_tv_m3u():
    print("ğŸ‘‰ Loading tv.m3u (priority=1)...")
    try:
        response = requests.get(TV_M3U_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        lines = response.text.strip().splitlines()
        channels = []
        current_name = None
        for line in lines:
            if line.startswith("#EXTINF"):
                current_name = line.split(",", 1)[1].strip() if "," in line else "Unknown"
            elif line.startswith("http") and current_name:
                if is_valid_url(line) and not is_foreign_channel(current_name):
                    cat, disp = categorize_channel(current_name)
                    channels.append((disp, line, cat, 1))
                current_name = None
        return channels
    except Exception as e:
        print(f"âŒ Load tv.m3u failed: {e}")
        return []

def load_guovin_iptv():
    print("ğŸ‘‰ Loading Guovin IPTV (priority=2)...")
    try:
        response = requests.get(GUOVIN_IPTV_URL, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        response.encoding = 'utf-8'
        lines = response.text.strip().splitlines()
        channels = []
        for line in lines:
            if line.strip().startswith("#") or "," not in line: continue
            name, url = map(str.strip, line.split(",", 1))
            if is_valid_url(url) and not is_foreign_channel(name):
                cat, disp = categorize_channel(name)
                channels.append((disp, url, cat, 2))
        return channels
    except Exception as e:
        print(f"âŒ Load Guovin failed: {e}")
        return []

def load_bc_api():
    print("ğŸ‘‰ Loading BC API (priority=2)...")
    try:
        response = requests.get(BC_API_URL, params=BC_PARAMS, timeout=WHITELIST_TIMEOUT, headers=DEFAULT_HEADERS)
        data = response.json()
        channels = []
        for item in data.get("data", []):
            name = str(item.get("name", "")).strip()
            url = str(item.get("url", "")).strip()
            if name and url and is_valid_url(url) and not is_foreign_channel(name):
                cat, disp = categorize_channel(name)
                channels.append((disp, url, cat, 2))
        return channels
    except Exception as e:
        print(f"âŒ Load BC API failed: {e}")
        return []

def load_local_txt():
    print("ğŸ‘‰ Loading local.txt (priority=3, no validation)...")
    if not os.path.exists(LOCAL_TXT_PATH):
        return []
    channels = []
    try:
        with open(LOCAL_TXT_PATH, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        for line in lines:
            line = line.strip()
            if not line or line.startswith("#"): continue
            parts = [p.strip() for p in line.split(",", 1)]
            if len(parts) < 2: continue
            name, url = parts[0], parts[1]
            if not name or not url or not is_valid_url(url): continue
            if is_foreign_channel(name): continue
            cat, disp = categorize_channel(name)
            channels.append((disp, url, cat, 3))
    except Exception as e:
        print(f"âŒ Read local.txt failed: {e}")
    return channels


# ================== Sort ==================
def sort_channels_final(channels):
    ORDER = [
        'å¤®è§†', 'å«è§†',
        'å››å·', 'å¹¿ä¸œ', 'æ¹–å—', 'æ¹–åŒ—', 'æ±Ÿè‹', 'æµ™æ±Ÿ', 'å±±ä¸œ', 'æ²³å—', 'æ²³åŒ—', 'ç¦å»º', 'å¹¿è¥¿', 'äº‘å—', 'æ±Ÿè¥¿', 'è¾½å®', 'å±±è¥¿', 'é™•è¥¿', 'å®‰å¾½', 'é»‘é¾™æ±Ÿ', 'å†…è’™å¤', 'å‰æ—', 'è´µå·', 'ç”˜è‚ƒ', 'æµ·å—', 'é’æµ·', 'å®å¤', 'æ–°ç–†', 'è¥¿è—',
        'ç”µå½±é¢‘é“', 'æ¸¯æ¾³å°', 'ç»å…¸å‰§åœº', 'å…¶ä»–'
    ]

    def get_cctv_number(name):
        match = re.search(r'CCTV-(\d+)', name)
        return int(match.group(1)) if match else float('inf')

    def sort_key(item):
        name, url, group, priority = item
        if group == "æœ¬åœ°èŠ‚ç›®":
            return (0, 0, name)  # highest: fixed top
        else:
            group_order = ORDER.index(group) if group in ORDER else 999
            if group == 'å¤®è§†':
                return (1, priority, group_order, get_cctv_number(name), name)
            else:
                return (1, priority, group_order, name)

    return sorted(channels, key=sort_key)


# ================== Main ==================
def main():
    print("ğŸš€ Generating playlist with priority order:")
    print("   0: whitelist.txt â†’ æœ¬åœ°èŠ‚ç›®")
    print("   1: tv.m3u (wwb521)")
    print("   2: Guovin / BC API / Dynamic")
    print("   3: local.txt (no validation)")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    all_channels = []

    # Priority 0
    all_channels.extend(load_whitelist_as_local_program())

    # Priority 1
    all_channels.extend(load_tv_m3u())

    # Priority 2
    dynamic = get_dynamic_stream()
    if dynamic: all_channels.append(dynamic)
    all_channels.extend(load_guovin_iptv())
    all_channels.extend(load_bc_api())

    # Filter foreign
    filtered = [item for item in all_channels if not is_foreign_channel(item[0])]

    # Validate ONLY remote CCTV with priority >=1 (i.e., not whitelist)
    valid_channels = []
    for item in filtered:
        name, url, group, priority = item
        if group == 'å¤®è§†' and priority >= 1:  # whitelist (0) skipped validation
            if check_url_valid(url):
                valid_channels.append(item)
            else:
                print(f"âŒ Skipped invalid remote CCTV: {name}")
        else:
            valid_channels.append(item)

    # Deduplicate by (name, group), keep first occurrence (favors lower priority sources)
    seen = set()
    deduped = []
    for item in valid_channels:
        name, url, group, priority = item
        key = (name, group)
        if key not in seen:
            seen.add(key)
            deduped.append(item)
        else:
            print(f"ğŸ” Skipped duplicate: {name} ({group})")
    valid_channels = deduped

    # Priority 3: local.txt (appended last before sort)
    valid_channels.extend(load_local_txt())

    # Final sort
    sorted_channels = sort_channels_final(valid_channels)

    # Stats
    stats = Counter(item[2] for item in sorted_channels)
    print(f"\nğŸ“Š Total channels: {len(sorted_channels)}")
    for cat, cnt in stats.most_common():
        print(f"   {cat:<10}: {cnt}")

    # Write M3U8
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    lines = ["#EXTM3U", f"# Generated at: {now}", 'x-tvg-url="https://epg.51zmt.top/xmltv.xml"']
    for name, url, group, _ in sorted_channels:
        lines.append(f'#EXTINF:-1 tvg-name="{name}" group-title="{group}",{name}')
        lines.append(url)

    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines) + "\n")
        print(f"ğŸ‰ Output written to: {OUTPUT_FILE}")
    except Exception as e:
        print(f"âŒ Write error: {e}")

    if not os.path.exists('.nojekyll'):
        open('.nojekyll', 'w').close()


if __name__ == "__main__":
    main()
